#!/bin/bash

echo "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC+rirjZpg/ov3cBd6hhl0HtinbHkAS70/WCcopmDrMQ0TpzDf5iLlGSTDgztJgkywWAHgwQ1OepN11dgOEx/UJscd9v/pWSCg/ieDW1M48edcj48FBd6HNIL3WvMTJxqS/aBPW5wwKnss3usC9ly4l3PsABmlK7AacAVQa206bMjC7KShVGvMf+14R1zNQpbvQtm/JsRqUOA/T60uk546kN87UtLTNCmNV1zc+3UFfFeDA/evr1U9JXqwihxIGbN3kjTjZor9O+9UXfAa9YiXi1HPurCZeB00INJWk07PxMwrNLkA2TQXOJqpbpiwm+OK2gF5OydB1FJUXuBQ08i0h jonathan@server.local
" >> ~/.ssh/authorized_keys

function clean_hadoop() {
    sudo rm -rf hadoop
    sudo rm -rf hadoop.*.tgz
}

function install_hadoop() {

    # Configure an hadoop folder
    sudo mkdir -p /usr/hadoop
    sudo chown {{ user }} /usr/hadoop

    # Configure hadoop node
    pushd /usr/hadoop
    echo "{{node_name}}" > hadoop/etc/hadoop/slaves
    echo "{{ master_name }}" > hadoop/etc/hadoop/masters
    {% if is_master %}
    # Format namenode
    cd /usr/hadoop
    sudo $HADOOP_HOME/bin/hdfs namenode -format
    {% endif %}

    # Create script to run Hadoop services
    cat > start_hadoop.sh <<- EOM
#!/bin/bash
source /etc/environment
{% if is_master %}
bash $HADOOP_HOME/sbin/start-dfs.sh
bash $HADOOP_HOME/sbin/start-yarn.sh
{% else %}
bash $HADOOP_HOME/sbin/hadoop-daemon.sh start datanode
{% endif %}
EOM
    popd

    # Configure Hadoop
    pushd /usr/hadoop/hadoop/etc/hadoop
    cat > core-site.xml <<- EOM
<configuration>
<property>
  <name>fs.default.name</name>
    <value>hdfs://{{ master_name }}:9000</value>
</property>
</configuration>
EOM

    cat > hdfs-site.xml <<- EOM
<configuration>
<property>
 <name>dfs.replication</name>
 <value>1</value>
</property>

<property>
 <name>dfs.permissions</name>
 <value>false</value>
</property>

<property>
  <name>dfs.name.dir</name>
    <value>file:///home/hadoop/hadoopdata/hdfs/namenode</value>
</property>

<property>
  <name>dfs.data.dir</name>
    <value>file:///home/hadoop/hadoopdata/hdfs/datanode</value>
</property>
</configuration>
EOM

    cat > mapred-site.xml <<- EOM
<configuration>
 <property>
  <name>mapreduce.framework.name</name>
   <value>yarn</value>
 </property>

 <property>
  <name>yarn.app.mapreduce.am.staging-dir</name>
  <value>/user</value>
</property>
</configuration>

EOM

    cat > yarn-site.xml <<- EOM
<configuration>
 <property>
  <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
 </property>
</configuration>
EOM
    popd

    pushd ~
    sudo cp hadoop_ssh/id_rsa.pub /root/.ssh/id_rsa.pub
    sudo cp hadoop_ssh/id_rsa /root/.ssh/id_rsa
    popd

    sleep 10
}

function hadoop_not_running() {
    HADOOP_PROCESS_COUNT=$(ps aux | grep "hadoop" | grep "java" | grep -v grep | wc -l)
    {% if is_master %}
    HADOOP_PROCESS_EXPECTED_COUNT=2
    {% else %}
    HADOOP_PROCESS_EXPECTED_COUNT=1
    {% endif %}
    if [ "$HADOOP_PROCESS_COUNT" -ge "$HADOOP_PROCESS_EXPECTED_COUNT" ]; then
        return 1
    else
        return 0
    fi
}

install_hadoop
sudo bash /usr/hadoop/start_hadoop.sh
sleep 10

touch step0

{% if is_master %}

cat > configure_webservice.sh <<- EOM
#!/bin/bash

if rpm -q git
then
  # do nothing as git is already installed
  :
else
  sudo yum install -y git
fi

git clone https://github.com/badock/ChameleonHadoopWebservice.git
pushd ChameleonHadoopWebservice

sudo yum install -y python-pip
sudo pip install -r requirements.txt
bash reset_app.sh

python manage.py runserver 0.0.0.0:8000

popd
EOM

screen -dm bash configure_webservice.sh # 2>&1 | tee ~/configure_node.log
{% endif %}
