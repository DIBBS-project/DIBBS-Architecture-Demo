#!/bin/bash

echo "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC+rirjZpg/ov3cBd6hhl0HtinbHkAS70/WCcopmDrMQ0TpzDf5iLlGSTDgztJgkywWAHgwQ1OepN11dgOEx/UJscd9v/pWSCg/ieDW1M48edcj48FBd6HNIL3WvMTJxqS/aBPW5wwKnss3usC9ly4l3PsABmlK7AacAVQa206bMjC7KShVGvMf+14R1zNQpbvQtm/JsRqUOA/T60uk546kN87UtLTNCmNV1zc+3UFfFeDA/evr1U9JXqwihxIGbN3kjTjZor9O+9UXfAa9YiXi1HPurCZeB00INJWk07PxMwrNLkA2TQXOJqpbpiwm+OK2gF5OydB1FJUXuBQ08i0h jonathan@server.local
" >> ~/.ssh/authorized_keys

function clean_hadoop() {
    echo "Cleaning running hadoop services"
    ps aux | grep java  | grep -v grep | awk '{print $2}' | sudo xargs kill -9

    echo "Cleaning existing data in hdfs"
    sudo rm -rf /home/hadoop/hadoopdata/hdfs/datanode

    echo "Cleaning hadoop logs"
    sudo rm -rf /usr/hadoop/hadoop/logs/*
}

function repair_permissions() {

    # Repair permissions
    pushd /usr/hadoop

    sudo chmod 777 start_hadoop.sh
    sudo chmod 777 reload.sh

    sudo chmod 777 hadoop/etc/hadoop
    sudo chmod 777 hadoop/etc/hadoop/*

    popd
}

function install_hadoop() {

    # Configure an hadoop folder
    sudo mkdir -p /usr/hadoop
    sudo chown {{ user }} /usr/hadoop

    # Configure hadoop node
    pushd /usr/hadoop
    echo "{{node_name}}" > hadoop/etc/hadoop/slaves
    echo "{{ master_name }}" > hadoop/etc/hadoop/masters

    # Create script to run Hadoop services
    cat > start_hadoop.sh <<- EOM
#!/bin/bash
source /etc/environment
{% if is_master %}
bash $HADOOP_HOME/sbin/start-dfs.sh
bash $HADOOP_HOME/sbin/start-yarn.sh
{% else %}
bash $HADOOP_HOME/sbin/hadoop-daemon.sh start datanode
{% endif %}
EOM
    popd

    # Configure Hadoop
    pushd /usr/hadoop/hadoop/etc/hadoop
    cat > core-site.xml <<- EOM
<configuration>
<property>
  <name>fs.default.name</name>
    <value>hdfs://{{ master_name }}:9000</value>
</property>
</configuration>
EOM

    cat > hdfs-site.xml <<- EOM
<configuration>
<property>
 <name>dfs.replication</name>
 <value>1</value>
</property>

<property>
 <name>dfs.permissions</name>
 <value>false</value>
</property>

<property>
  <name>dfs.name.dir</name>
    <value>file:///home/hadoop/hadoopdata/hdfs/namenode</value>
</property>

<property>
  <name>dfs.data.dir</name>
    <value>file:///home/hadoop/hadoopdata/hdfs/datanode</value>
</property>
</configuration>
EOM

    cat > mapred-site.xml <<- EOM
<configuration>
 <property>
  <name>mapreduce.framework.name</name>
   <value>yarn</value>
 </property>

 <property>
  <name>yarn.app.mapreduce.am.staging-dir</name>
  <value>/user</value>
</property>
</configuration>

EOM

    cat > yarn-site.xml <<- EOM
<configuration>
 <property>
  <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
 </property>
</configuration>
EOM

    {% if is_master %}
    # Format namenode
    sudo $HADOOP_HOME/bin/hdfs namenode -format
    {% endif %}

    popd

    pushd ~
    sudo cp hadoop_ssh/id_rsa.pub /root/.ssh/id_rsa.pub
    sudo cp hadoop_ssh/id_rsa /root/.ssh/id_rsa
    popd
}

function hadoop_not_running() {
    HADOOP_PROCESS_COUNT=$(ps aux | grep "hadoop" | grep "java" | grep -v grep | wc -l)
    {% if is_master %}
    HADOOP_PROCESS_EXPECTED_COUNT=2
    {% else %}
    HADOOP_PROCESS_EXPECTED_COUNT=1
    {% endif %}
    if [ "$HADOOP_PROCESS_COUNT" -ge "$HADOOP_PROCESS_EXPECTED_COUNT" ]; then
        return 1
    else
        return 0
    fi
}

function install_and_configure_agents() {
    pushd /usr/hadoop

    # Start a screen for the agents
    sudo yum install -y screen || true

    SCREEN_NAME="agents"
    COMMON_SCREEN_ARGS="-S $SCREEN_NAME -X screen"
    screen -AdmS $SCREEN_NAME


    ############################################################################
    # Install Process Manager Agent
    ############################################################################
    git clone https://github.com/DIBBS-project/process_manager_agent.git
    pushd process_manager_agent

    sudo yum install -y python-pip
    sudo pip install -r requirements.txt

    if rpm -q git
    then
        # do nothing as git is already installed
        :
    else
        sudo yum install -y git
    fi
    cat > configure_webservice.sh <<- EOM
#!/bin/bash

pushd /usr/hadoop/process_manager_agent
bash reset_app.sh
python manage.py runserver 0.0.0.0:8021

EOM

    screen $COMMON_SCREEN_ARGS -t pm_agent -dm bash /usr/hadoop/process_manager_agent/configure_webservice.sh
    popd

    ############################################################################
    # Install Resource Manager Agent
    ############################################################################
    git clone https://github.com/DIBBS-project/resource_manager_agent.git
    pushd resource_manager_agent

    sudo yum install -y python-pip
    sudo pip install -r requirements.txt

    if rpm -q git
    then
        # do nothing as git is already installed
        :
    else
        sudo yum install -y git
    fi
    cat > configure_webservice.sh <<- EOM
#!/bin/bash

pushd /usr/hadoop/resource_manager_agent
bash reset_app.sh
python manage.py runserver 0.0.0.0:8022

EOM

    screen $COMMON_SCREEN_ARGS -t rm_agent -dm bash /usr/hadoop/resource_manager_agent/configure_webservice.sh
    popd


    ############################################################################
    # Install Hadoop Webservice (legacy)
    ############################################################################
    git clone https://github.com/badock/ChameleonHadoopWebservice.git
    pushd ChameleonHadoopWebservice

    sudo yum install -y python-pip
    sudo pip install -r requirements.txt

    if rpm -q git
    then
        # do nothing as git is already installed
        :
    else
        sudo yum install -y git
    fi
    cat > configure_webservice.sh <<- EOM
#!/bin/bash

pushd /usr/hadoop/ChameleonHadoopWebservice
bash reset_app.sh
python manage.py runserver 0.0.0.0:8000

EOM

    screen $COMMON_SCREEN_ARGS -t hadoop_agent -dm bash /usr/hadoop/ChameleonHadoopWebservice/configure_webservice.sh
    popd

    popd
}

clean_hadoop
repair_permissions
install_hadoop
sudo bash /usr/hadoop/start_hadoop.sh

{% if is_master %}
install_and_configure_agents
{% endif %}
